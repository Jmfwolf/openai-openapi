# openai-java-client

OpenAI API
- API version: 1.2.0
  - Build date: 2023-03-27T16:09:35.007070044-07:00[America/Los_Angeles]

The OpenAI REST API

  For more information, please visit [https://help.openai.com](https://help.openai.com)

*Automatically generated by the [OpenAPI Generator](https://openapi-generator.tech)*


## Requirements

Building the API client library requires:
1. Java 1.8+
2. Maven (3.8.3+)/Gradle (7.2+)

## Installation

To install the API client library to your local Maven repository, simply execute:

```shell
mvn clean install
```

To deploy it to a remote Maven repository instead, configure the settings of the repository and execute:

```shell
mvn clean deploy
```

Refer to the [OSSRH Guide](http://central.sonatype.org/pages/ossrh-guide.html) for more information.

### Maven users

Add this dependency to your project's POM:

```xml
<dependency>
  <groupId>space.fraktured.ai</groupId>
  <artifactId>openai-java-client</artifactId>
  <version>1.2.0</version>
  <scope>compile</scope>
</dependency>
```

### Gradle users

Add this dependency to your project's build file:

```groovy
  repositories {
    mavenCentral()     // Needed if the 'openai-java-client' jar has been published to maven central.
    mavenLocal()       // Needed if the 'openai-java-client' jar has been published to the local maven repo.
  }

  dependencies {
     implementation "space.fraktured.ai:openai-java-client:1.2.0"
  }
```

### Others

At first generate the JAR by executing:

```shell
mvn clean package
```

Then manually install the following JARs:

* `target/openai-java-client-1.2.0.jar`
* `target/lib/*.jar`

## Getting Started

Please follow the [installation](#installation) instruction and execute the following Java code:

```java

// Import classes:
import space.fraktured.ai.client.ApiClient;
import space.fraktured.ai.client.ApiException;
import space.fraktured.ai.client.Configuration;
import space.fraktured.ai.client.models.*;
import space.fraktured.ai.client.api.AudioApi;

public class Example {
  public static void main(String[] args) {
    ApiClient defaultClient = Configuration.getDefaultApiClient();
    defaultClient.setBasePath("https://api.openai.com/v1");

    AudioApi apiInstance = new AudioApi(defaultClient);
    File _file = new File("/path/to/file"); // File | The audio file to transcribe, in one of these formats: mp3, mp4, mpeg, mpga, m4a, wav, or webm. 
    String model = "model_example"; // String | ID of the model to use. Only `whisper-1` is currently available. 
    String prompt = "prompt_example"; // String | An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language. 
    String responseFormat = "json"; // String | The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt. 
    BigDecimal temperature = new BigDecimal("0"); // BigDecimal | The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit. 
    String language = "language_example"; // String | The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency. 
    try {
      CreateTranscriptionResponse result = apiInstance.createTranscription(_file, model, prompt, responseFormat, temperature, language);
      System.out.println(result);
    } catch (ApiException e) {
      System.err.println("Exception when calling AudioApi#createTranscription");
      System.err.println("Status code: " + e.getCode());
      System.err.println("Reason: " + e.getResponseBody());
      System.err.println("Response headers: " + e.getResponseHeaders());
      e.printStackTrace();
    }
  }
}

```

## Documentation for API Endpoints

All URIs are relative to *https://api.openai.com/v1*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*AudioApi* | [**createTranscription**](docs/AudioApi.md#createTranscription) | **POST** /audio/transcriptions | Create Transcription
*AudioApi* | [**createTranslation**](docs/AudioApi.md#createTranslation) | **POST** /audio/translations | Create Translation
*ChatApi* | [**createChatCompletion**](docs/ChatApi.md#createChatCompletion) | **POST** /chat/completions | Create Chat Completion
*CompletionsApi* | [**createCompletion**](docs/CompletionsApi.md#createCompletion) | **POST** /completions | Create Completion
*EditsApi* | [**createEdit**](docs/EditsApi.md#createEdit) | **POST** /edits | Create Edit
*EmbeddingsApi* | [**createEmbedding**](docs/EmbeddingsApi.md#createEmbedding) | **POST** /embeddings | Create Embedding
*EnginesApi* | [**createAnswer**](docs/EnginesApi.md#createAnswer) | **POST** /answers | Create Answer
*EnginesApi* | [**createClassification**](docs/EnginesApi.md#createClassification) | **POST** /classifications | Create Classification
*EnginesApi* | [**createSearch**](docs/EnginesApi.md#createSearch) | **POST** /engines/{engine_id}/search | Create Search
*EnginesApi* | [**listEngines**](docs/EnginesApi.md#listEngines) | **GET** /engines | List Engines
*EnginesApi* | [**retrieveEngine**](docs/EnginesApi.md#retrieveEngine) | **GET** /engines/{engine_id} | Retrieve Engine
*FilesApi* | [**createFile**](docs/FilesApi.md#createFile) | **POST** /files | Create File
*FilesApi* | [**deleteFile**](docs/FilesApi.md#deleteFile) | **DELETE** /files/{file_id} | Delete File
*FilesApi* | [**downloadFile**](docs/FilesApi.md#downloadFile) | **GET** /files/{file_id}/content | Download File
*FilesApi* | [**listFiles**](docs/FilesApi.md#listFiles) | **GET** /files | List Files
*FilesApi* | [**retrieveFile**](docs/FilesApi.md#retrieveFile) | **GET** /files/{file_id} | Retrieve File
*FineTunesApi* | [**cancelFineTune**](docs/FineTunesApi.md#cancelFineTune) | **POST** /fine-tunes/{fine_tune_id}/cancel | Cancel Fine Tune
*FineTunesApi* | [**createFineTune**](docs/FineTunesApi.md#createFineTune) | **POST** /fine-tunes | Create Fine Tune
*FineTunesApi* | [**listFineTuneEvents**](docs/FineTunesApi.md#listFineTuneEvents) | **GET** /fine-tunes/{fine_tune_id}/events | List Fine Tune Events
*FineTunesApi* | [**listFineTunes**](docs/FineTunesApi.md#listFineTunes) | **GET** /fine-tunes | List Fine Tunes
*FineTunesApi* | [**retrieveFineTune**](docs/FineTunesApi.md#retrieveFineTune) | **GET** /fine-tunes/{fine_tune_id} | Retrieve Fine Tune
*ImagesApi* | [**createImage**](docs/ImagesApi.md#createImage) | **POST** /images/generations | Create Image
*ImagesApi* | [**createImageEdit**](docs/ImagesApi.md#createImageEdit) | **POST** /images/edits | Create Image Edit
*ImagesApi* | [**createImageVariation**](docs/ImagesApi.md#createImageVariation) | **POST** /images/variations | Create Image Variation
*ModelsApi* | [**deleteModel**](docs/ModelsApi.md#deleteModel) | **DELETE** /models/{model} | Delete Model
*ModelsApi* | [**listModels**](docs/ModelsApi.md#listModels) | **GET** /models | List Models
*ModelsApi* | [**retrieveModel**](docs/ModelsApi.md#retrieveModel) | **GET** /models/{model} | Retrieve Model
*ModerationsApi* | [**createModeration**](docs/ModerationsApi.md#createModeration) | **POST** /moderations | Create Moderation


## Documentation for Models

 - [ChatCompletionRequestMessage](docs/ChatCompletionRequestMessage.md)
 - [ChatCompletionResponseMessage](docs/ChatCompletionResponseMessage.md)
 - [CreateAnswerRequest](docs/CreateAnswerRequest.md)
 - [CreateAnswerRequestStop](docs/CreateAnswerRequestStop.md)
 - [CreateAnswerResponse](docs/CreateAnswerResponse.md)
 - [CreateAnswerResponseSelectedDocumentsInner](docs/CreateAnswerResponseSelectedDocumentsInner.md)
 - [CreateChatCompletionRequest](docs/CreateChatCompletionRequest.md)
 - [CreateChatCompletionRequestStop](docs/CreateChatCompletionRequestStop.md)
 - [CreateChatCompletionResponse](docs/CreateChatCompletionResponse.md)
 - [CreateChatCompletionResponseChoicesInner](docs/CreateChatCompletionResponseChoicesInner.md)
 - [CreateClassificationRequest](docs/CreateClassificationRequest.md)
 - [CreateClassificationResponse](docs/CreateClassificationResponse.md)
 - [CreateClassificationResponseSelectedExamplesInner](docs/CreateClassificationResponseSelectedExamplesInner.md)
 - [CreateCompletionRequest](docs/CreateCompletionRequest.md)
 - [CreateCompletionRequestPrompt](docs/CreateCompletionRequestPrompt.md)
 - [CreateCompletionRequestStop](docs/CreateCompletionRequestStop.md)
 - [CreateCompletionResponse](docs/CreateCompletionResponse.md)
 - [CreateCompletionResponseChoicesInner](docs/CreateCompletionResponseChoicesInner.md)
 - [CreateCompletionResponseChoicesInnerLogprobs](docs/CreateCompletionResponseChoicesInnerLogprobs.md)
 - [CreateCompletionResponseUsage](docs/CreateCompletionResponseUsage.md)
 - [CreateEditRequest](docs/CreateEditRequest.md)
 - [CreateEditResponse](docs/CreateEditResponse.md)
 - [CreateEmbeddingRequest](docs/CreateEmbeddingRequest.md)
 - [CreateEmbeddingRequestInput](docs/CreateEmbeddingRequestInput.md)
 - [CreateEmbeddingResponse](docs/CreateEmbeddingResponse.md)
 - [CreateEmbeddingResponseDataInner](docs/CreateEmbeddingResponseDataInner.md)
 - [CreateEmbeddingResponseUsage](docs/CreateEmbeddingResponseUsage.md)
 - [CreateFineTuneRequest](docs/CreateFineTuneRequest.md)
 - [CreateImageRequest](docs/CreateImageRequest.md)
 - [CreateModerationRequest](docs/CreateModerationRequest.md)
 - [CreateModerationRequestInput](docs/CreateModerationRequestInput.md)
 - [CreateModerationResponse](docs/CreateModerationResponse.md)
 - [CreateModerationResponseResultsInner](docs/CreateModerationResponseResultsInner.md)
 - [CreateModerationResponseResultsInnerCategories](docs/CreateModerationResponseResultsInnerCategories.md)
 - [CreateModerationResponseResultsInnerCategoryScores](docs/CreateModerationResponseResultsInnerCategoryScores.md)
 - [CreateSearchRequest](docs/CreateSearchRequest.md)
 - [CreateSearchResponse](docs/CreateSearchResponse.md)
 - [CreateSearchResponseDataInner](docs/CreateSearchResponseDataInner.md)
 - [CreateTranscriptionResponse](docs/CreateTranscriptionResponse.md)
 - [CreateTranslationResponse](docs/CreateTranslationResponse.md)
 - [DeleteFileResponse](docs/DeleteFileResponse.md)
 - [DeleteModelResponse](docs/DeleteModelResponse.md)
 - [Engine](docs/Engine.md)
 - [FineTune](docs/FineTune.md)
 - [FineTuneEvent](docs/FineTuneEvent.md)
 - [ImagesResponse](docs/ImagesResponse.md)
 - [ImagesResponseDataInner](docs/ImagesResponseDataInner.md)
 - [ListEnginesResponse](docs/ListEnginesResponse.md)
 - [ListFilesResponse](docs/ListFilesResponse.md)
 - [ListFineTuneEventsResponse](docs/ListFineTuneEventsResponse.md)
 - [ListFineTunesResponse](docs/ListFineTunesResponse.md)
 - [ListModelsResponse](docs/ListModelsResponse.md)
 - [Model](docs/Model.md)
 - [OpenAIFile](docs/OpenAIFile.md)


## Documentation for Authorization

All endpoints do not require authorization.
Authentication schemes defined for the API:

## Recommendation

It's recommended to create an instance of `ApiClient` per thread in a multithreaded environment to avoid any potential issues.

## Author



